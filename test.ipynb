{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1428a5b0-1df0-49e6-a4ca-b6f89dc57193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"llama3-8b-hn-rus\",\n",
    "    device_map='cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49d6a401-124d-4f64-9da6-05ecaed94c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d46f93659f34c7d83649aab6f5e3af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"llama3-8b-hn-rus\",\n",
    "    device_map='cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cd4a4cd-526e-456a-ab71-56f774a23074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "feb6add0-67ce-42d1-b53d-3f9fad42d6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Привет! Как дела?\\n\\nЯ хорошо. А ты?\\n\\nЯ также хорошо.\\n\\nЧто ты делал?\\n\\nЯ работал.\\n\\nЧто ты сделал?\\n\\nЯ работал.\\n\\nЧто ты сделал?\\n\\nЯ работал.\\n\\nЧто ты делал?\\n\\nЯ работал.\\n\\nЧто ты делал?\\n\\nЯ работал.\\n\\nЧто ты делал?\\n\\nЯ работал.\\n\\nЧто ты делал?\\n\\nЯ работал.\\n\\nЧто ты делал?\\n\\nЯ работал.\\n\\nЧто ты делал?\\n\\nЯ работал.\\n\\nЧто ты делал?\\n\\nЯ работал.\\n\\nЧто ты'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "# ]\n",
    "\n",
    "# prompt = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     tokenize=False,\n",
    "#     add_generation_prompt=True\n",
    "# )\n",
    "\n",
    "\n",
    "# terminators = [\n",
    "#     tokenizer.eos_token_id,\n",
    "#     tokenizer.convert_tokens_to_ids(\"<|im_end|>\"),\n",
    "#     tokenizer.convert_tokens_to_ids(\"<|eot_id|>\") # just in case, won't hurt\n",
    "# ]\n",
    "\n",
    "pipe(\n",
    "    # prompt,\n",
    "    \"Привет! Как дела?\",\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    max_new_tokens=128,\n",
    ")[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "295564a8-4a13-47dd-bd07-e0f3e0c5af85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594c3ca31c2b4e5f8870f40bb8606534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00007.safetensors:   0%|          | 0.00/2.57G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca3e28964514bd5bcf71f7206f0063d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 7 LFS files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67433a8594a438d899a53fcc4737e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5534cffbb32347c2b90edb85079485e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3124beb622a9437fb0f931a4b1c4ae07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00007.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab6f34d3a5f4c449bee30d02b41ff58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f7db1f4a024dff88dd843c07063663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc32ed87d65e45ef9ab93ef132c217d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datapaf/llama3_8b_hn_rus/commit/0802d9a698e87eacc508ebb2aa8f7a1ffe4eea73', commit_message='Upload LlamaForCausalLM', commit_description='', oid='0802d9a698e87eacc508ebb2aa8f7a1ffe4eea73', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('llama3_8b_hn_rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef369c1-63f8-46d0-8654-21ae9b8253d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncs_georgy",
   "language": "python",
   "name": "ncs_georgy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
